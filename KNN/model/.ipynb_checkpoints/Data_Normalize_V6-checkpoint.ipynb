{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018-7-23\n",
    "删除了OBV指标，因为OBV指标不固定，对最终的结果没有指导意义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division      #除数可以显示为float\n",
    "\n",
    "from six import StringIO    #使用聚宽readfile函数\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time                 #使用time stamp\n",
    "import datetime             \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "# 定义分组函数，对输入的数列按照n组进行划分\n",
    "def get_group(sample_data):\n",
    "    # 返回结果的数组\n",
    "    ret_group = []\n",
    "    if len(sample_data)!=0:\n",
    "        # 确定最大值、最小值\n",
    "        # 同时gap适当扩大，避免出现n+1的分组\n",
    "        d_mean = np.mean(sample_data)\n",
    "        d_std = np.std(sample_data)\n",
    "        ret_group = [math.floor(vals) if abs(math.floor(vals)) <=3 else 4*abs(math.floor(vals))/math.floor(vals) for vals in (np.array(sample_data) - d_mean)/(0.5*d_std)]\n",
    "    else:\n",
    "        ret_group =  []\n",
    "    return ret_group\n",
    "\n",
    "# 特征向量，共15个特征向量\n",
    "Col_Name = ['EMA_5', 'EMA_10', 'EMA_gap', 'KDJ_K', 'KDJ_D', 'KDJ_J', 'RSI', 'MACD_dif', 'MACD_dea', 'MACD_macd',\n",
    "                'MOM_12', 'MOM_25', 'MOM_gap', 'Long_Short_Rate_OBV', 'Volume']\n",
    "\n",
    "# 生成总的列表\n",
    "Col_Total = []\n",
    "for col in Col_Name:\n",
    "    Col_Total.append(col)\n",
    "    \n",
    "    # 生成前两天的值\n",
    "    for day_count_i in range(1, 3):\n",
    "        Col_Total.append(str(str(col) + \"_pre\" + str(day_count_i)))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理文件：raw_data1.csv\n",
      "步骤1：开始处理：EMA_5\n",
      "步骤1：开始处理：EMA_10\n",
      "步骤1：开始处理：EMA_gap\n",
      "步骤1：开始处理：KDJ_K\n",
      "步骤1：开始处理：KDJ_D\n",
      "步骤1：开始处理：KDJ_J\n",
      "步骤1：开始处理：RSI\n",
      "步骤1：开始处理：MACD_dif\n",
      "步骤1：开始处理：MACD_dea\n",
      "步骤1：开始处理：MACD_macd\n",
      "步骤1：开始处理：MOM_12\n",
      "步骤1：开始处理：MOM_25\n",
      "步骤1：开始处理：MOM_gap\n",
      "步骤1：开始处理：OBV\n",
      "步骤1：开始处理：Long_Short_Rate_OBV\n",
      "步骤1：开始处理：Volume\n",
      "完成步骤1\n",
      "完成步骤2\n",
      "步骤3：开始处理：EMA_5\n",
      "步骤3：开始处理：EMA_10\n",
      "步骤3：开始处理：EMA_gap\n",
      "步骤3：开始处理：KDJ_K\n",
      "步骤3：开始处理：KDJ_D\n",
      "步骤3：开始处理：KDJ_J\n",
      "步骤3：开始处理：RSI\n",
      "步骤3：开始处理：MACD_dif\n",
      "步骤3：开始处理：MACD_dea\n",
      "步骤3：开始处理：MACD_macd\n",
      "步骤3：开始处理：MOM_12\n",
      "步骤3：开始处理：MOM_25\n",
      "步骤3：开始处理：MOM_gap\n",
      "步骤3：开始处理：OBV\n",
      "步骤3：开始处理：Long_Short_Rate_OBV\n",
      "步骤3：开始处理：Volume\n",
      "完成步骤3\n",
      "生成均方差列表\n",
      "开始处理文件：raw_data2.csv\n",
      "步骤1：开始处理：EMA_5\n",
      "步骤1：开始处理：EMA_10\n",
      "步骤1：开始处理：EMA_gap\n",
      "步骤1：开始处理：KDJ_K\n",
      "步骤1：开始处理：KDJ_D\n",
      "步骤1：开始处理：KDJ_J\n",
      "步骤1：开始处理：RSI\n",
      "步骤1：开始处理：MACD_dif\n",
      "步骤1：开始处理：MACD_dea\n",
      "步骤1：开始处理：MACD_macd\n",
      "步骤1：开始处理：MOM_12\n",
      "步骤1：开始处理：MOM_25\n",
      "步骤1：开始处理：MOM_gap\n",
      "步骤1：开始处理：OBV\n",
      "步骤1：开始处理：Long_Short_Rate_OBV\n",
      "步骤1：开始处理：Volume\n",
      "完成步骤1\n",
      "完成步骤2\n",
      "步骤3：开始处理：EMA_5\n",
      "步骤3：开始处理：EMA_10\n",
      "步骤3：开始处理：EMA_gap\n",
      "步骤3：开始处理：KDJ_K\n",
      "步骤3：开始处理：KDJ_D\n",
      "步骤3：开始处理：KDJ_J\n",
      "步骤3：开始处理：RSI\n",
      "步骤3：开始处理：MACD_dif\n",
      "步骤3：开始处理：MACD_dea\n",
      "步骤3：开始处理：MACD_macd\n",
      "步骤3：开始处理：MOM_12\n",
      "步骤3：开始处理：MOM_25\n",
      "步骤3：开始处理：MOM_gap\n",
      "步骤3：开始处理：OBV\n",
      "步骤3：开始处理：Long_Short_Rate_OBV\n",
      "步骤3：开始处理：Volume\n",
      "完成步骤3\n",
      "生成均方差列表\n",
      "开始处理文件：raw_data3.csv\n",
      "步骤1：开始处理：EMA_5\n",
      "步骤1：开始处理：EMA_10\n",
      "步骤1：开始处理：EMA_gap\n",
      "步骤1：开始处理：KDJ_K\n",
      "步骤1：开始处理：KDJ_D\n",
      "步骤1：开始处理：KDJ_J\n",
      "步骤1：开始处理：RSI\n",
      "步骤1：开始处理：MACD_dif\n",
      "步骤1：开始处理：MACD_dea\n",
      "步骤1：开始处理：MACD_macd\n",
      "步骤1：开始处理：MOM_12\n",
      "步骤1：开始处理：MOM_25\n",
      "步骤1：开始处理：MOM_gap\n",
      "步骤1：开始处理：OBV\n",
      "步骤1：开始处理：Long_Short_Rate_OBV\n",
      "步骤1：开始处理：Volume\n",
      "完成步骤1\n",
      "完成步骤2\n",
      "步骤3：开始处理：EMA_5\n",
      "步骤3：开始处理：EMA_10\n",
      "步骤3：开始处理：EMA_gap\n",
      "步骤3：开始处理：KDJ_K\n",
      "步骤3：开始处理：KDJ_D\n",
      "步骤3：开始处理：KDJ_J\n",
      "步骤3：开始处理：RSI\n",
      "步骤3：开始处理：MACD_dif\n",
      "步骤3：开始处理：MACD_dea\n",
      "步骤3：开始处理：MACD_macd\n",
      "步骤3：开始处理：MOM_12\n",
      "步骤3：开始处理：MOM_25\n",
      "步骤3：开始处理：MOM_gap\n",
      "步骤3：开始处理：OBV\n",
      "步骤3：开始处理：Long_Short_Rate_OBV\n",
      "步骤3：开始处理：Volume\n",
      "完成步骤3\n",
      "生成均方差列表\n",
      "开始处理文件：raw_data4.csv\n",
      "步骤1：开始处理：EMA_5\n",
      "步骤1：开始处理：EMA_10\n",
      "步骤1：开始处理：EMA_gap\n",
      "步骤1：开始处理：KDJ_K\n",
      "步骤1：开始处理：KDJ_D\n",
      "步骤1：开始处理：KDJ_J\n",
      "步骤1：开始处理：RSI\n",
      "步骤1：开始处理：MACD_dif\n",
      "步骤1：开始处理：MACD_dea\n",
      "步骤1：开始处理：MACD_macd\n",
      "步骤1：开始处理：MOM_12\n",
      "步骤1：开始处理：MOM_25\n",
      "步骤1：开始处理：MOM_gap\n",
      "步骤1：开始处理：OBV\n",
      "步骤1：开始处理：Long_Short_Rate_OBV\n",
      "步骤1：开始处理：Volume\n",
      "完成步骤1\n",
      "完成步骤2\n",
      "步骤3：开始处理：EMA_5\n",
      "步骤3：开始处理：EMA_10\n",
      "步骤3：开始处理：EMA_gap\n",
      "步骤3：开始处理：KDJ_K\n",
      "步骤3：开始处理：KDJ_D\n",
      "步骤3：开始处理：KDJ_J\n",
      "步骤3：开始处理：RSI\n",
      "步骤3：开始处理：MACD_dif\n",
      "步骤3：开始处理：MACD_dea\n",
      "步骤3：开始处理：MACD_macd\n",
      "步骤3：开始处理：MOM_12\n",
      "步骤3：开始处理：MOM_25\n",
      "步骤3：开始处理：MOM_gap\n",
      "步骤3：开始处理：OBV\n",
      "步骤3：开始处理：Long_Short_Rate_OBV\n",
      "步骤3：开始处理：Volume\n",
      "完成步骤3\n",
      "生成均方差列表\n",
      "开始处理文件：raw_data5.csv\n",
      "步骤1：开始处理：EMA_5\n",
      "步骤1：开始处理：EMA_10\n",
      "步骤1：开始处理：EMA_gap\n",
      "步骤1：开始处理：KDJ_K\n",
      "步骤1：开始处理：KDJ_D\n",
      "步骤1：开始处理：KDJ_J\n",
      "步骤1：开始处理：RSI\n",
      "步骤1：开始处理：MACD_dif\n",
      "步骤1：开始处理：MACD_dea\n",
      "步骤1：开始处理：MACD_macd\n",
      "步骤1：开始处理：MOM_12\n",
      "步骤1：开始处理：MOM_25\n",
      "步骤1：开始处理：MOM_gap\n",
      "步骤1：开始处理：OBV\n",
      "步骤1：开始处理：Long_Short_Rate_OBV\n",
      "步骤1：开始处理：Volume\n",
      "完成步骤1\n",
      "完成步骤2\n",
      "步骤3：开始处理：EMA_5\n",
      "步骤3：开始处理：EMA_10\n",
      "步骤3：开始处理：EMA_gap\n",
      "步骤3：开始处理：KDJ_K\n",
      "步骤3：开始处理：KDJ_D\n",
      "步骤3：开始处理：KDJ_J\n",
      "步骤3：开始处理：RSI\n",
      "步骤3：开始处理：MACD_dif\n",
      "步骤3：开始处理：MACD_dea\n",
      "步骤3：开始处理：MACD_macd\n",
      "步骤3：开始处理：MOM_12\n",
      "步骤3：开始处理：MOM_25\n",
      "步骤3：开始处理：MOM_gap\n",
      "步骤3：开始处理：OBV\n",
      "步骤3：开始处理：Long_Short_Rate_OBV\n",
      "步骤3：开始处理：Volume\n",
      "完成步骤3\n",
      "生成均方差列表\n",
      "开始处理文件：raw_data6.csv\n",
      "步骤1：开始处理：EMA_5\n",
      "步骤1：开始处理：EMA_10\n",
      "步骤1：开始处理：EMA_gap\n",
      "步骤1：开始处理：KDJ_K\n",
      "步骤1：开始处理：KDJ_D\n",
      "步骤1：开始处理：KDJ_J\n",
      "步骤1：开始处理：RSI\n",
      "步骤1：开始处理：MACD_dif\n",
      "步骤1：开始处理：MACD_dea\n",
      "步骤1：开始处理：MACD_macd\n",
      "步骤1：开始处理：MOM_12\n",
      "步骤1：开始处理：MOM_25\n",
      "步骤1：开始处理：MOM_gap\n",
      "步骤1：开始处理：OBV\n",
      "步骤1：开始处理：Long_Short_Rate_OBV\n",
      "步骤1：开始处理：Volume\n",
      "完成步骤1\n",
      "完成步骤2\n",
      "步骤3：开始处理：EMA_5\n",
      "步骤3：开始处理：EMA_10\n",
      "步骤3：开始处理：EMA_gap\n",
      "步骤3：开始处理：KDJ_K\n",
      "步骤3：开始处理：KDJ_D\n",
      "步骤3：开始处理：KDJ_J\n",
      "步骤3：开始处理：RSI\n",
      "步骤3：开始处理：MACD_dif\n",
      "步骤3：开始处理：MACD_dea\n",
      "步骤3：开始处理：MACD_macd\n",
      "步骤3：开始处理：MOM_12\n",
      "步骤3：开始处理：MOM_25\n",
      "步骤3：开始处理：MOM_gap\n",
      "步骤3：开始处理：OBV\n",
      "步骤3：开始处理：Long_Short_Rate_OBV\n",
      "步骤3：开始处理：Volume\n",
      "完成步骤3\n",
      "生成均方差列表\n",
      "开始处理文件：raw_data7.csv\n",
      "步骤1：开始处理：EMA_5\n",
      "步骤1：开始处理：EMA_10\n",
      "步骤1：开始处理：EMA_gap\n",
      "步骤1：开始处理：KDJ_K\n",
      "步骤1：开始处理：KDJ_D\n",
      "步骤1：开始处理：KDJ_J\n",
      "步骤1：开始处理：RSI\n",
      "步骤1：开始处理：MACD_dif\n",
      "步骤1：开始处理：MACD_dea\n",
      "步骤1：开始处理：MACD_macd\n",
      "步骤1：开始处理：MOM_12\n",
      "步骤1：开始处理：MOM_25\n",
      "步骤1：开始处理：MOM_gap\n",
      "步骤1：开始处理：OBV\n",
      "步骤1：开始处理：Long_Short_Rate_OBV\n",
      "步骤1：开始处理：Volume\n",
      "完成步骤1\n",
      "完成步骤2\n",
      "步骤3：开始处理：EMA_5\n",
      "步骤3：开始处理：EMA_10\n",
      "步骤3：开始处理：EMA_gap\n",
      "步骤3：开始处理：KDJ_K\n",
      "步骤3：开始处理：KDJ_D\n",
      "步骤3：开始处理：KDJ_J\n",
      "步骤3：开始处理：RSI\n",
      "步骤3：开始处理：MACD_dif\n",
      "步骤3：开始处理：MACD_dea\n",
      "步骤3：开始处理：MACD_macd\n",
      "步骤3：开始处理：MOM_12\n",
      "步骤3：开始处理：MOM_25\n",
      "步骤3：开始处理：MOM_gap\n",
      "步骤3：开始处理：OBV\n",
      "步骤3：开始处理：Long_Short_Rate_OBV\n",
      "步骤3：开始处理：Volume\n",
      "完成步骤3\n",
      "生成均方差列表\n",
      "开始处理文件：raw_data8.csv\n",
      "步骤1：开始处理：EMA_5\n",
      "步骤1：开始处理：EMA_10\n",
      "步骤1：开始处理：EMA_gap\n",
      "步骤1：开始处理：KDJ_K\n",
      "步骤1：开始处理：KDJ_D\n",
      "步骤1：开始处理：KDJ_J\n",
      "步骤1：开始处理：RSI\n",
      "步骤1：开始处理：MACD_dif\n",
      "步骤1：开始处理：MACD_dea\n",
      "步骤1：开始处理：MACD_macd\n",
      "步骤1：开始处理：MOM_12\n",
      "步骤1：开始处理：MOM_25\n",
      "步骤1：开始处理：MOM_gap\n",
      "步骤1：开始处理：OBV\n",
      "步骤1：开始处理：Long_Short_Rate_OBV\n",
      "步骤1：开始处理：Volume\n",
      "完成步骤1\n",
      "完成步骤2\n",
      "步骤3：开始处理：EMA_5\n",
      "步骤3：开始处理：EMA_10\n",
      "步骤3：开始处理：EMA_gap\n",
      "步骤3：开始处理：KDJ_K\n",
      "步骤3：开始处理：KDJ_D\n",
      "步骤3：开始处理：KDJ_J\n",
      "步骤3：开始处理：RSI\n",
      "步骤3：开始处理：MACD_dif\n",
      "步骤3：开始处理：MACD_dea\n",
      "步骤3：开始处理：MACD_macd\n",
      "步骤3：开始处理：MOM_12\n",
      "步骤3：开始处理：MOM_25\n",
      "步骤3：开始处理：MOM_gap\n",
      "步骤3：开始处理：OBV\n",
      "步骤3：开始处理：Long_Short_Rate_OBV\n",
      "步骤3：开始处理：Volume\n",
      "完成步骤3\n",
      "生成均方差列表\n",
      "开始处理文件：raw_data9.csv\n",
      "步骤1：开始处理：EMA_5\n",
      "步骤1：开始处理：EMA_10\n",
      "步骤1：开始处理：EMA_gap\n",
      "步骤1：开始处理：KDJ_K\n",
      "步骤1：开始处理：KDJ_D\n",
      "步骤1：开始处理：KDJ_J\n",
      "步骤1：开始处理：RSI\n",
      "步骤1：开始处理：MACD_dif\n",
      "步骤1：开始处理：MACD_dea\n",
      "步骤1：开始处理：MACD_macd\n",
      "步骤1：开始处理：MOM_12\n",
      "步骤1：开始处理：MOM_25\n",
      "步骤1：开始处理：MOM_gap\n",
      "步骤1：开始处理：OBV\n",
      "步骤1：开始处理：Long_Short_Rate_OBV\n",
      "步骤1：开始处理：Volume\n",
      "完成步骤1\n",
      "完成步骤2\n",
      "步骤3：开始处理：EMA_5\n",
      "步骤3：开始处理：EMA_10\n",
      "步骤3：开始处理：EMA_gap\n",
      "步骤3：开始处理：KDJ_K\n",
      "步骤3：开始处理：KDJ_D\n",
      "步骤3：开始处理：KDJ_J\n",
      "步骤3：开始处理：RSI\n",
      "步骤3：开始处理：MACD_dif\n",
      "步骤3：开始处理：MACD_dea\n",
      "步骤3：开始处理：MACD_macd\n",
      "步骤3：开始处理：MOM_12\n",
      "步骤3：开始处理：MOM_25\n",
      "步骤3：开始处理：MOM_gap\n",
      "步骤3：开始处理：OBV\n",
      "步骤3：开始处理：Long_Short_Rate_OBV\n",
      "步骤3：开始处理：Volume\n",
      "完成步骤3\n",
      "生成均方差列表\n",
      "开始处理文件：raw_data10.csv\n",
      "步骤1：开始处理：EMA_5\n",
      "步骤1：开始处理：EMA_10\n",
      "步骤1：开始处理：EMA_gap\n",
      "步骤1：开始处理：KDJ_K\n",
      "步骤1：开始处理：KDJ_D\n",
      "步骤1：开始处理：KDJ_J\n",
      "步骤1：开始处理：RSI\n",
      "步骤1：开始处理：MACD_dif\n",
      "步骤1：开始处理：MACD_dea\n",
      "步骤1：开始处理：MACD_macd\n",
      "步骤1：开始处理：MOM_12\n",
      "步骤1：开始处理：MOM_25\n",
      "步骤1：开始处理：MOM_gap\n",
      "步骤1：开始处理：OBV\n",
      "步骤1：开始处理：Long_Short_Rate_OBV\n",
      "步骤1：开始处理：Volume\n",
      "完成步骤1\n",
      "完成步骤2\n",
      "步骤3：开始处理：EMA_5\n",
      "步骤3：开始处理：EMA_10\n",
      "步骤3：开始处理：EMA_gap\n",
      "步骤3：开始处理：KDJ_K\n",
      "步骤3：开始处理：KDJ_D\n",
      "步骤3：开始处理：KDJ_J\n",
      "步骤3：开始处理：RSI\n",
      "步骤3：开始处理：MACD_dif\n",
      "步骤3：开始处理：MACD_dea\n",
      "步骤3：开始处理：MACD_macd\n",
      "步骤3：开始处理：MOM_12\n",
      "步骤3：开始处理：MOM_25\n",
      "步骤3：开始处理：MOM_gap\n",
      "步骤3：开始处理：OBV\n",
      "步骤3：开始处理：Long_Short_Rate_OBV\n",
      "步骤3：开始处理：Volume\n",
      "完成步骤3\n",
      "生成均方差列表\n",
      "打印均方差列表\n"
     ]
    }
   ],
   "source": [
    "# 均方差列表\n",
    "MS_List_pd = pd.DataFrame()\n",
    "\n",
    "# 开始处理文件\n",
    "for file_i in range(1,11,1):\n",
    "    Data_Total = pd.DataFrame()\n",
    "\n",
    "    file_name = \"raw_data%d.csv\" % (int(file_i))\n",
    "    Data_Total = pd.read_csv(file_name)\n",
    "\n",
    "    print \"开始处理文件：%s\" % str(file_name)\n",
    "\n",
    "    Stock_list = set(list(Data_Total['code']))\n",
    "\n",
    "\n",
    "\n",
    "    #############################################  1、 增加一个前1-2天的值      ############################################################\n",
    "    for col in Col_Name:\n",
    "        print \"步骤1：开始处理：%s\" % str(col)\n",
    "        \n",
    "        # 修改列属性为float,之后数据透视需要\n",
    "        Data_Total[col] = Data_Total[col].astype(float)\n",
    "        for day_count_i in range(1, 3):\n",
    "\n",
    "            Data_Total.loc[:, str(str(col) + \"_pre\" + str(day_count_i))] = None\n",
    "            # 修改列属性为float,之后数据透视需要\n",
    "            Data_Total[str(str(col) + \"_pre\" + str(day_count_i))] = Data_Total[str(str(col) + \"_pre\" + str(day_count_i))].astype(float)\n",
    "            \n",
    "            for stock_name in Stock_list:\n",
    "                temp = []\n",
    "                temp = list(Data_Total.loc[Data_Total['code'] == stock_name, col])\n",
    "                for i in range(0, day_count_i):\n",
    "                    temp.insert(0,0)\n",
    "                    \n",
    "                Data_Total.loc[Data_Total['code'] == stock_name, str(str(col) + \"_pre\" + str(day_count_i))] = np.array(temp[:-day_count_i])\n",
    "\n",
    "    print \"完成步骤1\"\n",
    "\n",
    "    #############################################  2、 删除无效数据，更改数据类型      ############################################################\n",
    "    # 更改平局为-1\n",
    "    Data_Total.loc[Data_Total['win_rate'] == 0, \"win_rate\"] = -1\n",
    "\n",
    "    # 删除前60，后10的数据\n",
    "    for stock_name in Stock_list:\n",
    "        Data_Total = Data_Total.drop(Data_Total[Data_Total['code'] == stock_name].iloc[:60].index, axis=0)\n",
    "        Data_Total = Data_Total.drop(Data_Total[Data_Total['code'] == stock_name].iloc[-10:].index, axis=0)\n",
    "\n",
    "    # 统一操作，删除价格为0的数据\n",
    "    Data_Total = Data_Total.drop(Data_Total[Data_Total['price'] == 0].index, axis=0)\n",
    "    Data_Total = Data_Total.drop(Data_Total[Data_Total['Volume'] == 0].index, axis=0)\n",
    "\n",
    "    print \"完成步骤2\"\n",
    "\n",
    "    #############################################  3、 归一化数据      ############################################################\n",
    "    Data_Normalize = pd.DataFrame()\n",
    "\n",
    "    # 赋值列：code、date，avg_price，win_rate\n",
    "    Data_Normalize = Data_Total.loc[:, ['code', 'date', 'price', 'win_rate']]\n",
    "\n",
    "    for col in Col_Name:\n",
    "        print \"步骤3：开始处理：%s\" % str(col)\n",
    "\n",
    "        # 处理原始列数据\n",
    "        Data_Normalize.loc[:, col] = None\n",
    "\n",
    "        for stock_name in Stock_list:\n",
    "            Data_Normalize.loc[Data_Normalize['code'] == stock_name, col] \\\n",
    "                = np.array(get_group(list(Data_Total[Data_Total['code'] == stock_name][col])))\n",
    "\n",
    "        # 处理扩展的列数据\n",
    "        for day_count_i in range(1, 3):\n",
    "            Data_Normalize.loc[:, str(str(col) + \"_pre\" + str(day_count_i))] = None\n",
    "\n",
    "\n",
    "            for stock_name in Stock_list:\n",
    "                Data_Normalize.loc[Data_Normalize['code'] == stock_name, str(str(col) + \"_pre\" + str(day_count_i))] \\\n",
    "                    = np.array(get_group(\n",
    "                    list(Data_Total[Data_Total['code'] == stock_name][str(str(col) + \"_pre\" + str(day_count_i))])))\n",
    "\n",
    "    print \"完成步骤3\"\n",
    "    #############################################  4、生成文件     ############################################################\n",
    "\n",
    "    file_name_normalize = 'Data_Washed%d.csv' % (int(file_i))\n",
    "    Data_Normalize.to_csv(file_name_normalize)\n",
    "    \n",
    "    \n",
    "    #############################################  5、生成均方差列表    ############################################################\n",
    "    print \"生成均方差列表\"\n",
    "    MS_List_pd = pd.concat([MS_List_pd, pd.pivot_table(Data_Total,index=[\"code\"],values=Col_Total,aggfunc=[np.mean,np.std])])\n",
    "\n",
    "    \n",
    "##############################################  6、打印保存均方差列表    ############################################################\n",
    "print '打印均方差列表'\n",
    "MS_List_pd.to_csv(\"MS_List.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
