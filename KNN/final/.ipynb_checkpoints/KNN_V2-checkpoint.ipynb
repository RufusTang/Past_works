{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division      #除数可以显示为float\n",
    "\n",
    "from six import StringIO    #使用聚宽readfile函数\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time                 #使用time stamp\n",
    "import datetime             \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "\n",
    "import talib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 功能：输入Pandas数据，生成对应的指标数据\n",
    "# 输入：\n",
    "# input_data_pd：输入的原始Pandas数据\n",
    "# 格式：必须包含的列包括：'code','date','close','high','low','volume','open'，用于计算指标\n",
    "# 输出：\n",
    "# ret_pd：输出Pandas数据\n",
    "# ret_col：返回的特征向量\n",
    "# 计算 15个指标，用于计算的指标包括：\n",
    "# 'EMA_5', 'EMA_10', 'EMA_gap', 'KDJ_K', 'KDJ_D', 'KDJ_J', 'RSI', 'MACD_dif', 'MACD_dea', 'MACD_macd','MOM_12', 'MOM_25', 'MOM_gap', 'Long_Short_Rate_OBV', 'Volume'\n",
    "\n",
    "def Indicator_Generate(input_data_pd):\n",
    "    \n",
    "    ret_pd = pd.DataFrame()\n",
    "    ret_pd = input_data_pd\n",
    "    \n",
    "    # 返回的特征向量\n",
    "    ret_col = ['EMA_5', 'EMA_10', 'EMA_gap', 'KDJ_K', 'KDJ_D', 'KDJ_J', 'RSI', 'MACD_dif', 'MACD_dea', 'MACD_macd','MOM_12', 'MOM_25', 'MOM_gap', 'Long_Short_Rate_OBV', 'Volume']\n",
    "    \n",
    "    stock_list = set(list(input_data_pd['code']))\n",
    "    \n",
    "    # 计算相应的值\n",
    "    for stock_name in stock_list:\n",
    "    \n",
    "        ################################   1、生成MACD信息   ###################################################\n",
    "        ret_pd[\"MACD_dif\"] = None\n",
    "        ret_pd[\"MACD_dea\"] = None\n",
    "        ret_pd[\"MACD_macd\"] = None\n",
    "        \n",
    "        for stock_name in stock_list:\n",
    "            dif = []\n",
    "            dea = []\n",
    "            macd = []\n",
    "\n",
    "            macd_price = ret_pd.loc[ret_pd['code'] == stock_name,\"close\"]\n",
    "\n",
    "            dif, dea, macd = talib.MACD(np.array(macd_price), fastperiod=5, slowperiod=10, signalperiod=5)\n",
    "\n",
    "            ret_pd.loc[ret_pd['code'] == stock_name,\"MACD_dif\"] = np.array(dif)\n",
    "            ret_pd.loc[ret_pd['code'] == stock_name,\"MACD_dea\"] = np.array(dea)\n",
    "            ret_pd.loc[ret_pd['code'] == stock_name,\"MACD_macd\"] = np.array(macd)\n",
    "\n",
    "\n",
    "        ################################   2、生成均线信息   ###################################################\n",
    "        ret_pd[\"EMA_5\"] = None\n",
    "        ret_pd[\"EMA_10\"] = None\n",
    "        ret_pd[\"EMA_gap\"] = None\n",
    "\n",
    "        \n",
    "        \n",
    "        for stock_name in stock_list:\n",
    "            ema_5 = []\n",
    "            ema_10 = []\n",
    "            ema_gap = []\n",
    "\n",
    "\n",
    "            ema_price = ret_pd.loc[ret_pd['code'] == stock_name,\"close\"]\n",
    "            ema_5 = talib.EMA(np.array(ema_price), timeperiod=5)\n",
    "            ema_10 = talib.EMA(np.array(ema_price), timeperiod=10)\n",
    "            ema_gap = talib.EMA(np.array(ema_price), timeperiod=5) - talib.EMA(np.array(ema_price), timeperiod=10)\n",
    "\n",
    "\n",
    "            ret_pd.loc[ret_pd['code'] == stock_name,\"EMA_5\"] = np.array(ema_5)\n",
    "            ret_pd.loc[ret_pd['code'] == stock_name,\"EMA_10\"] = np.array(ema_10)\n",
    "            ret_pd.loc[ret_pd['code'] == stock_name,\"EMA_gap\"] = np.array(ema_gap)\n",
    "\n",
    "\n",
    "        ################################   3、生成KDJ指标   ###################################################\n",
    "        ret_pd[\"KDJ_K\"] = None\n",
    "        ret_pd[\"KDJ_D\"] = None    \n",
    "        ret_pd[\"KDJ_J\"] = None\n",
    "        \n",
    "        \n",
    "        \n",
    "        for stock_name in set(stock_list):\n",
    "            K_values = []\n",
    "            D_values = []\n",
    "            J_values = []\n",
    "\n",
    "            kdj_price = ret_pd.loc[ret_pd['code'] == stock_name,['high','low','close']]\n",
    "            kdj_price = kdj_price.fillna(0)\n",
    "\n",
    "                #                  (Today's Close - LowestLow)\n",
    "                # FASTK(Kperiod) = --------------------------- * 100\n",
    "                #                   (HighestHigh - LowestLow)\n",
    "\n",
    "                # FASTD(FastDperiod) = MA Smoothed FASTK over FastDperiod\n",
    "\n",
    "                # SLOWK(SlowKperiod) = MA Smoothed FASTK over SlowKperiod\n",
    "\n",
    "                # SLOWD(SlowDperiod) = MA Smoothed SLOWK over SlowDperiod\n",
    "\n",
    "            K_values, D_values = talib.STOCH(kdj_price['high'].values,\n",
    "                                               kdj_price['low'].values,\n",
    "                                               kdj_price['close'].values,\n",
    "                                               fastk_period=9,\n",
    "                                               slowk_period=3,\n",
    "                                               slowk_matype=0,\n",
    "                                               slowd_period=3,\n",
    "                                               slowd_matype=0)\n",
    "\n",
    "\n",
    "            J_values = 3 * np.array(K_values) - 2 * np.array(D_values)\n",
    "\n",
    "            ret_pd.loc[ret_pd['code'] == stock_name,\"KDJ_K\"] = np.array(K_values)\n",
    "            ret_pd.loc[ret_pd['code'] == stock_name,\"KDJ_D\"] = np.array(D_values)\n",
    "            ret_pd.loc[ret_pd['code'] == stock_name,\"KDJ_J\"] = np.array(J_values)\n",
    "\n",
    "\n",
    "        ################################   4、开始计算RSI指标   ###################################################\n",
    "        ret_pd[\"RSI\"] = None\n",
    "\n",
    "        \n",
    "        for stock_name in set(stock_list):\n",
    "            rsi_values = []\n",
    "\n",
    "            rsi_price = ret_pd.loc[ret_pd['code'] == stock_name,['high','low','close']]\n",
    "\n",
    "            rsi_price = rsi_price.fillna(0)\n",
    "\n",
    "            rsi_values = talib.RSI(np.array(rsi_price['close']), 12)       #RSI的天数一般是6、12、24\n",
    "\n",
    "            ret_pd.loc[ret_pd['code'] == stock_name,\"RSI\"] = np.array(rsi_values)\n",
    "\n",
    "        ret_pd = ret_pd.fillna(0)\n",
    "\n",
    "        ################################   5、开始计算动量指标“MOM”   ###################################################\n",
    "        ret_pd[\"MOM_12\"] = None\n",
    "        ret_pd[\"MOM_25\"] = None\n",
    "        # 选择一条10日均线作为中间线，判断\n",
    "        ret_pd[\"MOM_gap\"] = None\n",
    "\n",
    "        \n",
    "        for stock_name in set(stock_list):\n",
    "\n",
    "            MOM_values = []\n",
    "            MOM_gap_values = []\n",
    "\n",
    "            mom_price = list(ret_pd[ret_pd['code'] == stock_name]['close'])\n",
    "\n",
    "\n",
    "            MOM_12_values = talib.MOM(np.array(mom_price), timeperiod = 12)\n",
    "\n",
    "            MOM_25_values = talib.MOM(np.array(mom_price), timeperiod = 25)\n",
    "\n",
    "            MOM_gap_values = MOM_25_values - MOM_12_values\n",
    "\n",
    "            ret_pd.loc[ret_pd['code'] == stock_name,\"MOM_12\"] = np.array(MOM_12_values)\n",
    "            ret_pd.loc[ret_pd['code'] == stock_name,\"MOM_25\"] = np.array(MOM_25_values)\n",
    "\n",
    "            ret_pd.loc[ret_pd['code'] == stock_name,\"MOM_gap\"] = np.array(MOM_gap_values)\n",
    "\n",
    "\n",
    "        ################################   6、开始计算能量指标OBV   ###################################################\n",
    "        ret_pd[\"Long_Short_Rate_OBV\"] = None\n",
    "\n",
    "\n",
    "        \n",
    "        for stock_name in set(stock_list):\n",
    "            OBV_values = []\n",
    "\n",
    "\n",
    "            obv_price = ret_pd.loc[ret_pd['code'] == stock_name,['high','low','close','volume']]\n",
    "\n",
    "            obv_price = obv_price.fillna(0)\n",
    "\n",
    "            # 通过价格进行调整\n",
    "            Long_Short_Rate_OBV_values = []\n",
    "\n",
    "\n",
    "            OBV_gap = 0 \n",
    "            for i in range(0,len(obv_price['close'])):\n",
    "                OBV_gap = ((obv_price['close'].values[i]-obv_price['low'].values[i]) \\\n",
    "                               -(obv_price['high'].values[i]-obv_price['close'].values[i])) \\\n",
    "                              /(obv_price['high'].values[i]-obv_price['low'].values[i])\n",
    "\n",
    "\n",
    "                if np.isnan(OBV_gap):\n",
    "                    OBV_gap = 0\n",
    "\n",
    "                if i == 0:\n",
    "                    Long_Short_Rate_OBV_values.append(obv_price['volume'].values[i])\n",
    "                else:\n",
    "                    Long_Short_Rate_OBV_values.append(float(OBV_gap)*float(obv_price['volume'].values[i]))\n",
    "\n",
    "            ret_pd.loc[ret_pd['code'] == stock_name,\"Long_Short_Rate_OBV\"] = np.array(Long_Short_Rate_OBV_values)       \n",
    "\n",
    "\n",
    "        ################################  7、开始计算成交量   ###################################################\n",
    "        ret_pd[\"Volume\"] = None\n",
    "\n",
    "        for stock_name in set(stock_list):\n",
    "\n",
    "            Volume_price = ret_pd.loc[ret_pd['code'] == stock_name,['high','low','close','volume']]\n",
    "\n",
    "            ret_pd.loc[ret_pd['code'] == stock_name,\"Volume\"] = np.array(Volume_price['volume'])       \n",
    "\n",
    "        ret_pd = ret_pd.fillna(0)\n",
    "    \n",
    "    return ret_pd,ret_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 功能：数据数据后，按照日期，进行相应的扩展，将前几天的数据进行扩展，分别显示前N天的数据\n",
    "# 输入：\n",
    "# input_data_pd：输入的原始Pandas数据，函数中必须包含'code'，'date','win_rate'\n",
    "# day_count：需要向前扩展的天数\n",
    "# Col_Name：需要扩展的列，避免将'code'、'date','win_rate'也同步扩展了\n",
    "# 输出：\n",
    "# ret_pd：输出扩展后的Pandas数据\n",
    "# Col_Total:输出扩展后的列表列名\n",
    "def Indicator_Extend(input_data_pd,day_count,Col_Name):\n",
    "\n",
    "    # 生成总的列表\n",
    "    Col_Total = []\n",
    "    for col in Col_Name:\n",
    "        Col_Total.append(col)\n",
    "        \n",
    "        # 生成前两天的值\n",
    "        for day_count_i in range(1, 3):\n",
    "            Col_Total.append(str(str(col) + \"_pre\" + str(day_count_i)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 初始化数据\n",
    "    ret_pd = pd.DataFrame(columns = (['code','date'] +Col_Total))    \n",
    "    ret_pd[['code','date','win_rate']] =  input_data_pd.loc[:,['code','date','win_rate']]\n",
    "    \n",
    "    ret_pd[Col_Name] =  input_data_pd.loc[:,Col_Name]\n",
    "    Stock_list = set(list(input_data_pd['code']))\n",
    "    \n",
    "    ##############################################  1、 赋值前1-2天的值      ############################################################\n",
    "\n",
    "    for col in Col_Name:\n",
    "\n",
    "        # 修改列属性为float,之后数据透视需要\n",
    "        ret_pd[col] = ret_pd[col].astype(float)\n",
    "\n",
    "        for day_count_i in range(1, day_count + 1):\n",
    "\n",
    "            ret_pd.loc[:, str(str(col) + \"_pre\" + str(day_count_i))] = None\n",
    "\n",
    "            # 修改列属性为float,之后数据透视需要\n",
    "            ret_pd[str(str(col) + \"_pre\" + str(day_count_i))] = ret_pd[str(str(col) + \"_pre\" + str(day_count_i))].astype(float)\n",
    "\n",
    "            for stock_name in Stock_list:\n",
    "                temp = []\n",
    "                temp = list(input_data_pd.loc[input_data_pd['code'] == stock_name, col])\n",
    "                for i in range(0, day_count_i):\n",
    "                    temp.insert(0,0)\n",
    "\n",
    "                \n",
    "                ret_pd.loc[input_data_pd['code'] == stock_name, str(str(col) + \"_pre\" + str(day_count_i))] = np.array(temp[:-day_count_i])\n",
    "\n",
    "\n",
    "    return ret_pd,Col_Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 功能：删除不必要的数据，包括\n",
    "# 1、前60个数据\n",
    "# 2、后10个数据\n",
    "# 3、成交量为0的数据\n",
    "# 返回：\n",
    "# 删除完成后的数据\n",
    "def delete_data(input_data_pd):\n",
    "\n",
    "    ret_pd = input_data_pd.copy()\n",
    "    \n",
    "    # 删除无效数据，准备进行数据处理\n",
    "    stock_list = set(list(ret_pd['code']))\n",
    "    # 更改平局为-1\n",
    "    ret_pd.loc[ret_pd['win_rate'] == 0, \"win_rate\"] = -1\n",
    "    for stock_name in stock_list:\n",
    "        # 删除前60，后10的数据\n",
    "        ret_pd = ret_pd.drop(ret_pd[ret_pd['code'] == stock_name].iloc[:60].index, axis=0)\n",
    "        ret_pd = ret_pd.drop(ret_pd[ret_pd['code'] == stock_name].iloc[-10:].index, axis=0)\n",
    "        # 统一操作，删除价格为0的数据\n",
    "        ret_pd = ret_pd.drop(ret_pd[ret_pd['Volume'] == 0].index, axis=0)\n",
    "    return ret_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize_into_pd\n",
    "# 功能：将数据进行归一化，逐股票生成相应的离散值\n",
    "# 离散原则：按照正态分布的规则，按照均值、方差的值，分阶段进行离散\n",
    "# input_data_pd：pandas数据结构，多行数据，记录样本归一化前的原始数据\n",
    "# cols：列名，归一化的相应列名\n",
    "# 返回值：\n",
    "# ret_pd：按照原则离散化后的Pandas数组\n",
    "# MS_pd：返回按照股票、cols列为维度的Pandas数据\n",
    "\n",
    "def normalize_into_pd(input_data_pd,cols):\n",
    "    # 定义分组函数，对输入的数列按照n组进行划分\n",
    "    # 输入数据为list类型\n",
    "    def get_group(sample_data):\n",
    "        # 返回结果的数组\n",
    "        ret_group = []\n",
    "        if len(sample_data)!=0:\n",
    "            # 确定最大值、最小值\n",
    "            # 同时gap适当扩大，避免出现n+1的分组\n",
    "            d_mean = np.mean(sample_data)\n",
    "            d_std = np.std(sample_data)\n",
    "            ret_group = [math.floor(vals) if abs(math.floor(vals)) <=3 else 4*abs(math.floor(vals))/math.floor(vals) for vals in (np.array(sample_data) - d_mean)/(0.5*d_std)]\n",
    "        else:\n",
    "            ret_group =  []\n",
    "        return ret_group\n",
    "    \n",
    "    # 变量赋初值，其中input_data_pd必须包含code列\n",
    "    Stock_list = set(list(input_data_pd['code']))\n",
    "    ret_pd = pd.DataFrame(columns = ['code','date'] + cols)\n",
    "    MS_pd = pd.DataFrame()\n",
    "\n",
    "    ret_pd['code'] = np.array(input_data_pd['code'])\n",
    "    ret_pd['date'] = np.array(input_data_pd['date'])\n",
    "    ret_pd['win_rate'] = np.array(input_data_pd['win_rate'])\n",
    "    \n",
    "    # 逐列开始进行数据处理\n",
    "    for col in cols:\n",
    "\n",
    "        # 处理原始列数据\n",
    "\n",
    "        for stock_name in Stock_list:\n",
    "            ret_pd.loc[ret_pd['code'] == stock_name, col] \\\n",
    "                = np.array(get_group(list(input_data_pd[input_data_pd['code'] == stock_name][col])))\n",
    "    \n",
    "        \n",
    "    MS_pd = pd.pivot_table(input_data_pd, index=[\"code\"], values=cols, aggfunc=[np.mean,np.std])\n",
    "\n",
    "    return ret_pd,MS_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize_by_list使用索引表对数据进行归一化，生成模型可识别的样本\n",
    "# file_name：索引文件名，记录均值方差，需遵守相应表格列名称规则\n",
    "# sample_data_pd：pandas数据结构，仅一行，记录样本归一化前的原始数据\n",
    "# stock_name：股票名，用于去索引文件中查找对应的数据\n",
    "# cols：列名，归一化的相应列名\n",
    "\n",
    "def normalize_by_list(MS_pd,sample_data_series,stock_name,cols):\n",
    "    # ret_pd是返回的pd数组\n",
    "    ret_pd = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    # 创建列，赋值为None\n",
    "    ret_pd[cols] = None\n",
    "    \n",
    "       \n",
    "    # 逐列计算对应归一化的值\n",
    "    for col in cols:\n",
    "        mean = 0\n",
    "        std = 0\n",
    "        \n",
    "        # 查找表中的数据\n",
    "        mean = MS_pd.loc[MS_pd['code']==stock_name,str(col+\"_mean\")]\n",
    "        std = MS_pd.loc[MS_pd['code']==stock_name,str(col+\"_std\")]\n",
    "\n",
    "        # 计算\n",
    "        val = (float(sample_data_series[col]) - mean)/(0.5*std)\n",
    "        \n",
    "        temp = 0\n",
    "        if abs(math.floor(val)) <=3:\n",
    "            temp = math.floor(val)\n",
    "        else:\n",
    "            temp = 4*val/abs(val)\n",
    "\n",
    "        ret_pd.loc[:,col] = np.array([float(temp)])\n",
    "\n",
    "    return ret_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:172: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# 从基础数据表中读取数据，生成指标数据\n",
    "data_test = pd.DataFrame()\n",
    "data_test,Col_Name = Indicator_Generate(pd.read_csv(\"raw_data_price1.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 63)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 扩展数据，生成多列数据\n",
    "data_extend_test = pd.DataFrame()\n",
    "data_extend_test,Col_Total = Indicator_Extend(data_test,3,Col_Name)\n",
    "data_extend_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52858, 63)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除无效数据，更改“平”为“负”\n",
    "data_delete = delete_data(data_extend_test)\n",
    "data_delete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化，并且生成均方差列表\n",
    "data_normalize = pd.DataFrame()\n",
    "MS_pd = pd.DataFrame()\n",
    "data_normalize,MS_pd = normalize_into_pd(data_delete,Col_Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code\n",
       "000001.XSHE    13.146855\n",
       "000002.XSHE    14.107902\n",
       "000060.XSHE    10.988804\n",
       "000063.XSHE    18.746680\n",
       "000069.XSHE     7.660405\n",
       "000100.XSHE     3.274741\n",
       "000157.XSHE     7.258858\n",
       "000166.XSHE     7.819640\n",
       "000333.XSHE    34.864180\n",
       "000338.XSHE    24.362258\n",
       "000402.XSHE     8.285357\n",
       "000413.XSHE    11.978396\n",
       "000415.XSHE     9.165302\n",
       "000423.XSHE    47.492618\n",
       "000425.XSHE    12.258484\n",
       "000503.XSHE    23.285562\n",
       "000538.XSHE    72.993682\n",
       "000540.XSHE     8.666715\n",
       "000559.XSHE    11.131535\n",
       "000568.XSHE    34.814623\n",
       "000623.XSHE    24.716076\n",
       "000625.XSHE    11.749457\n",
       "000627.XSHE     5.898539\n",
       "000630.XSHE    11.964755\n",
       "000651.XSHE    28.692380\n",
       "000671.XSHE     9.700301\n",
       "000709.XSHE     3.278898\n",
       "000723.XSHE    11.354159\n",
       "000725.XSHE     2.969591\n",
       "000728.XSHE    14.719109\n",
       "Name: EMA_10, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MS_pd['mean']['EMA_10']['000001.XSHE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS_pd.to_csv(\"MS_list.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提示：这里需要对均方差列表进行手工操作，以便之后进行操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始进行量化预测\n",
    "from __future__ import division      #除数可以显示为float\n",
    "from six import StringIO    #使用聚宽readfile函数\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time                 #使用time stamp\n",
    "import datetime             \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "\n",
    "# 最基本的KNN算法\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 导入样本拆分模块\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 导入KNN半径算法\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "\n",
    "# 评分函数\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 交叉评分函数\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正常回归：股票名称: 000568.XSHE; 正确率:0.562500；正例个数:160；正确个数:90\n",
      "正常回归：股票名称: 000100.XSHE; 正确率:0.509259；正例个数:108；正确个数:55\n",
      "正常回归：股票名称: 000630.XSHE; 正确率:0.500000；正例个数:68；正确个数:34\n",
      "正常回归：股票名称: 000559.XSHE; 正确率:0.507812；正例个数:128；正确个数:65\n",
      "正常回归：股票名称: 000413.XSHE; 正确率:0.483607；正例个数:122；正确个数:59\n",
      "正常回归：股票名称: 000728.XSHE; 正确率:0.450382；正例个数:131；正确个数:59\n",
      "正常回归：股票名称: 000002.XSHE; 正确率:0.572917；正例个数:96；正确个数:55\n",
      "正常回归：股票名称: 000540.XSHE; 正确率:0.590361；正例个数:83；正确个数:49\n",
      "正常回归：股票名称: 000402.XSHE; 正确率:0.628319；正例个数:113；正确个数:71\n",
      "正常回归：股票名称: 000060.XSHE; 正确率:0.608333；正例个数:120；正确个数:73\n",
      "正常回归：股票名称: 000538.XSHE; 正确率:0.593985；正例个数:133；正确个数:79\n",
      "正常回归：股票名称: 000425.XSHE; 正确率:0.403846；正例个数:104；正确个数:42\n",
      "正常回归：股票名称: 000625.XSHE; 正确率:0.425926；正例个数:108；正确个数:46\n",
      "正常回归：股票名称: 000069.XSHE; 正确率:0.565891；正例个数:129；正确个数:73\n",
      "正常回归：股票名称: 000725.XSHE; 正确率:0.516129；正例个数:124；正确个数:64\n",
      "正常回归：股票名称: 000415.XSHE; 正确率:0.520548；正例个数:73；正确个数:38\n",
      "正常回归：股票名称: 000423.XSHE; 正确率:0.548148；正例个数:135；正确个数:74\n",
      "正常回归：股票名称: 000503.XSHE; 正确率:0.482014；正例个数:139；正确个数:67\n",
      "正常回归：股票名称: 000623.XSHE; 正确率:0.464912；正例个数:114；正确个数:53\n",
      "正常回归：股票名称: 000001.XSHE; 正确率:0.482143；正例个数:56；正确个数:27\n",
      "正常回归：股票名称: 000333.XSHE; 正确率:0.555556；正例个数:81；正确个数:45\n",
      "正常回归：股票名称: 000627.XSHE; 正确率:0.530303；正例个数:132；正确个数:70\n",
      "正常回归：股票名称: 000651.XSHE; 正确率:0.614035；正例个数:114；正确个数:70\n",
      "正常回归：股票名称: 000063.XSHE; 正确率:0.569536；正例个数:151；正确个数:86\n",
      "正常回归：股票名称: 000709.XSHE; 正确率:0.571429；正例个数:98；正确个数:56\n",
      "正常回归：股票名称: 000166.XSHE; 正确率:0.500000；正例个数:4；正确个数:2\n",
      "正常回归：股票名称: 000723.XSHE; 正确率:0.625000；正例个数:128；正确个数:80\n",
      "正常回归：股票名称: 000338.XSHE; 正确率:0.571429；正例个数:147；正确个数:84\n",
      "正常回归：股票名称: 000671.XSHE; 正确率:0.581395；正例个数:129；正确个数:75\n",
      "正常回归：股票名称: 000157.XSHE; 正确率:0.469880；正例个数:83；正确个数:39\n"
     ]
    }
   ],
   "source": [
    "Stock_list = set(list(data_normalize['code']))\n",
    "score_stock_dict = {}\n",
    "k = 11\n",
    "for stock_name in Stock_list:\n",
    "\n",
    "    # 测试数据\n",
    "    X =  np.array(data_normalize.loc[data_normalize['code'] == stock_name,Col_Total])\n",
    "    # 测试结果\n",
    "    y = np.array(data_normalize.loc[data_normalize['code'] == stock_name,\"win_rate\"])\n",
    "\n",
    "    # 分别生成训练数据、测试数据\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)\n",
    "    \n",
    "    # 单一模型预测\n",
    "    # 训练模型\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    score_stock_dict[stock_name] = [precision_score(y_test,y_pred ,average='binary'),int(len(y_test[y_pred == 1])),int(sum(y_test[y_pred == 1] ==1))]\n",
    "    print \"正常回归：股票名称: %s; 正确率:%f；正例个数:%d；正确个数:%d\"%(str(stock_name),score_stock_dict[stock_name][0],score_stock_dict[stock_name][1],score_stock_dict[stock_name][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_stock_pd = pd.DataFrame.from_dict(score_stock_dict, orient='index',columns = ['TP','Predict_counts','Correct_counts'])\n",
    "score_stock_pd.to_csv(\"stock_rate.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始针对数据进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000568.XSHE\n",
      "2018-06-27\n",
      "000100.XSHE\n",
      "2018-06-27\n",
      "000630.XSHE\n",
      "2018-06-27\n",
      "000559.XSHE\n",
      "2018-06-27\n",
      "000413.XSHE\n",
      "2018-06-27\n",
      "000728.XSHE\n",
      "2018-06-27\n",
      "000002.XSHE\n",
      "2018-06-27\n",
      "000540.XSHE\n",
      "2018-06-27\n",
      "000402.XSHE\n",
      "2018-06-27\n",
      "000060.XSHE\n",
      "2018-06-27\n",
      "000538.XSHE\n",
      "2018-06-27\n",
      "000425.XSHE\n",
      "2018-06-27\n",
      "000625.XSHE\n",
      "2018-06-27\n",
      "000069.XSHE\n",
      "2018-06-27\n",
      "000725.XSHE\n",
      "2018-06-27\n",
      "000415.XSHE\n",
      "2018-06-27\n",
      "000423.XSHE\n",
      "2018-06-27\n",
      "000503.XSHE\n",
      "2018-06-27\n",
      "000623.XSHE\n",
      "2018-06-27\n",
      "000001.XSHE\n",
      "2018-06-27\n",
      "000333.XSHE\n",
      "2018-06-27\n",
      "000627.XSHE\n",
      "2018-06-27\n",
      "000651.XSHE\n",
      "2018-06-27\n",
      "000063.XSHE\n",
      "2018-06-27\n",
      "000709.XSHE\n",
      "2018-06-27\n",
      "000166.XSHE\n",
      "2018-06-27\n",
      "000723.XSHE\n",
      "2018-06-27\n",
      "000338.XSHE\n",
      "2018-06-27\n",
      "000671.XSHE\n",
      "2018-06-27\n",
      "000157.XSHE\n",
      "2018-06-27\n"
     ]
    }
   ],
   "source": [
    "Stock_list = set(list(data_normalize['code']))\n",
    "Buy_List_Dict = {}\n",
    "k = 11\n",
    "MS_pd = pd.read_csv(\"MS_list.csv\")\n",
    "\n",
    "\n",
    "for stock_name in Stock_list:\n",
    "\n",
    "    # 测试数据\n",
    "    X =  np.array(data_normalize.loc[data_normalize['code'] == stock_name,Col_Total])\n",
    "    # 测试结果\n",
    "    y = np.array(data_normalize.loc[data_normalize['code'] == stock_name,\"win_rate\"])\n",
    "\n",
    "    # 分别生成训练数据、测试数据\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0)\n",
    "    \n",
    "    # 单一模型预测\n",
    "    # 训练模型\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    predict_data_series = pd.Series(data_extend_test.loc[data_extend_test['code'] == stock_name,Col_Total].iloc[-1,:])\n",
    "    \n",
    "    \n",
    "    predict_data_normal_pd = normalize_by_list(MS_pd,predict_data_series,stock_name,Col_Total)\n",
    "    \n",
    "    y_pred = model.predict([list(predict_data_normal_pd.iloc[0,:])])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    print stock_name \n",
    "    print str(data_extend_test.loc[data_extend_test['code'] == stock_name,'date'][-20:-19].values[0])\n",
    "    predict_data_normal_pd.to_csv(stock_name+str(data_extend_test.loc[data_extend_test['code'] == stock_name,'date'][-20:-19].values[0])+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 13] Permission denied: 'verify.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-9adeb5387e39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_normalize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"verify.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   1743\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1745\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\io\\formats\\csvs.pyc\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    154\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m    155\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\io\\common.pyc\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;31m# Python 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 13] Permission denied: 'verify.csv'"
     ]
    }
   ],
   "source": [
    "data_normalize.to_csv(\"verify.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取模块进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进入聚宽进行验证"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
